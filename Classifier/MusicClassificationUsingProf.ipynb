{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-01-28 15:03:19--  http://dept-info.labri.fr/~hanna/Pub/features_adapte.csv\n",
      "Résolution de dept-info.labri.fr (dept-info.labri.fr)… 147.210.9.83, 2001:660:6101:404::81\n",
      "Connexion à dept-info.labri.fr (dept-info.labri.fr)|147.210.9.83|:80… connecté.\n",
      "requête HTTP transmise, en attente de la réponse… 200 OK\n",
      "Taille : 951108530 (907M) [text/csv]\n",
      "Enregistre : «features_adapte.csv»\n",
      "\n",
      "features_adapte.csv 100%[===================>] 907,05M  9,04MB/s    ds 1m 41s  \n",
      "\n",
      "2020-01-28 15:05:00 (8,99 MB/s) - «features_adapte.csv» enregistré [951108530/951108530]\n",
      "\n",
      "--2020-01-28 15:05:00--  http://dept-info.labri.fr/~hanna/Pub/features_head.csv\n",
      "Résolution de dept-info.labri.fr (dept-info.labri.fr)… 147.210.9.83, 2001:660:6101:404::81\n",
      "Connexion à dept-info.labri.fr (dept-info.labri.fr)|147.210.9.83|:80… connecté.\n",
      "requête HTTP transmise, en attente de la réponse… 200 OK\n",
      "Taille : 19134 (19K) [text/csv]\n",
      "Enregistre : «features_head.csv»\n",
      "\n",
      "features_head.csv   100%[===================>]  18,69K  --.-KB/s    ds 0,002s  \n",
      "\n",
      "2020-01-28 15:05:00 (7,59 MB/s) - «features_head.csv» enregistré [19134/19134]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ce notebook contient les mêmes méthodes que le premier mais executées sur les features extraites par Mr. Hanna\n",
    "# contrairement à l'autre qui repose sur notre propre extraction avec librosa\n",
    "\n",
    "# Executez cette case si vous n'avez pas les données dans le répertoire\n",
    "\n",
    "# !wget http://dept-info.labri.fr/~hanna/Pub/features_adapte.csv\n",
    "# !wget http://dept-info.labri.fr/~hanna/Pub/features_head.csv\n",
    "# !wget http://dept-info.labri.fr/~hanna/Pub/train_clean.csv\n",
    "# !wget http://dept-info.labri.fr/~hanna/Pub/test_clean.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['feature', 'chroma_cens', 'chroma_cens.1', 'chroma_cens.2',\n",
      "       'chroma_cens.3', 'chroma_cens.4', 'chroma_cens.5', 'chroma_cens.6',\n",
      "       'chroma_cens.7', 'chroma_cens.8',\n",
      "       ...\n",
      "       'tonnetz.39', 'tonnetz.40', 'tonnetz.41', 'zcr', 'zcr.1', 'zcr.2',\n",
      "       'zcr.3', 'zcr.4', 'zcr.5', 'zcr.6'],\n",
      "      dtype='object', length=519)\n",
      "#################\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_id</th>\n",
       "      <th>genre_id</th>\n",
       "      <th>01</th>\n",
       "      <th>02</th>\n",
       "      <th>03</th>\n",
       "      <th>04</th>\n",
       "      <th>05</th>\n",
       "      <th>06</th>\n",
       "      <th>07</th>\n",
       "      <th>08</th>\n",
       "      <th>...</th>\n",
       "      <th>04.41</th>\n",
       "      <th>05.41</th>\n",
       "      <th>06.41</th>\n",
       "      <th>01.70</th>\n",
       "      <th>01.71</th>\n",
       "      <th>01.72</th>\n",
       "      <th>01.73</th>\n",
       "      <th>01.74</th>\n",
       "      <th>01.75</th>\n",
       "      <th>01.76</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>3544</td>\n",
       "      <td>133294</td>\n",
       "      <td>6</td>\n",
       "      <td>0.133676</td>\n",
       "      <td>1.219621</td>\n",
       "      <td>1.041329</td>\n",
       "      <td>0.659568</td>\n",
       "      <td>0.661551</td>\n",
       "      <td>0.840704</td>\n",
       "      <td>1.389098</td>\n",
       "      <td>1.094413</td>\n",
       "      <td>...</td>\n",
       "      <td>0.063345</td>\n",
       "      <td>0.016298</td>\n",
       "      <td>0.018405</td>\n",
       "      <td>3.186660</td>\n",
       "      <td>0.575195</td>\n",
       "      <td>0.092824</td>\n",
       "      <td>0.066406</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>1.689548</td>\n",
       "      <td>0.080830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1023</td>\n",
       "      <td>40237</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.634775</td>\n",
       "      <td>-0.452372</td>\n",
       "      <td>-0.081961</td>\n",
       "      <td>0.020517</td>\n",
       "      <td>-0.575869</td>\n",
       "      <td>-0.431036</td>\n",
       "      <td>-0.426676</td>\n",
       "      <td>-0.382549</td>\n",
       "      <td>...</td>\n",
       "      <td>0.097534</td>\n",
       "      <td>0.017034</td>\n",
       "      <td>0.017351</td>\n",
       "      <td>16.264420</td>\n",
       "      <td>0.691406</td>\n",
       "      <td>0.073199</td>\n",
       "      <td>0.055176</td>\n",
       "      <td>0.009766</td>\n",
       "      <td>2.996620</td>\n",
       "      <td>0.062984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3698</td>\n",
       "      <td>140872</td>\n",
       "      <td>3</td>\n",
       "      <td>-1.081832</td>\n",
       "      <td>-1.001203</td>\n",
       "      <td>0.902922</td>\n",
       "      <td>0.164892</td>\n",
       "      <td>-0.614164</td>\n",
       "      <td>-0.655986</td>\n",
       "      <td>-0.119395</td>\n",
       "      <td>5.273300</td>\n",
       "      <td>...</td>\n",
       "      <td>0.152206</td>\n",
       "      <td>0.030529</td>\n",
       "      <td>0.025080</td>\n",
       "      <td>30.582483</td>\n",
       "      <td>0.436523</td>\n",
       "      <td>0.025041</td>\n",
       "      <td>0.014160</td>\n",
       "      <td>0.004883</td>\n",
       "      <td>5.332044</td>\n",
       "      <td>0.046589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>272</td>\n",
       "      <td>11419</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.768838</td>\n",
       "      <td>-0.667095</td>\n",
       "      <td>-0.604739</td>\n",
       "      <td>-0.180145</td>\n",
       "      <td>-0.846874</td>\n",
       "      <td>-0.380538</td>\n",
       "      <td>-0.984623</td>\n",
       "      <td>-0.918730</td>\n",
       "      <td>...</td>\n",
       "      <td>0.140241</td>\n",
       "      <td>0.036428</td>\n",
       "      <td>0.028642</td>\n",
       "      <td>35.297848</td>\n",
       "      <td>0.337891</td>\n",
       "      <td>0.030125</td>\n",
       "      <td>0.024414</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.388410</td>\n",
       "      <td>0.027061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>24331</td>\n",
       "      <td>6</td>\n",
       "      <td>-0.504906</td>\n",
       "      <td>-0.532965</td>\n",
       "      <td>-0.224551</td>\n",
       "      <td>-0.419990</td>\n",
       "      <td>-0.410279</td>\n",
       "      <td>0.823258</td>\n",
       "      <td>0.188249</td>\n",
       "      <td>-0.768032</td>\n",
       "      <td>...</td>\n",
       "      <td>0.168203</td>\n",
       "      <td>0.034010</td>\n",
       "      <td>0.031814</td>\n",
       "      <td>295.583923</td>\n",
       "      <td>0.840332</td>\n",
       "      <td>0.021472</td>\n",
       "      <td>0.014648</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.710932</td>\n",
       "      <td>0.040361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1950</td>\n",
       "      <td>69198</td>\n",
       "      <td>2</td>\n",
       "      <td>0.750938</td>\n",
       "      <td>0.909248</td>\n",
       "      <td>4.442852</td>\n",
       "      <td>2.286593</td>\n",
       "      <td>1.375715</td>\n",
       "      <td>2.297371</td>\n",
       "      <td>-0.726958</td>\n",
       "      <td>-0.612376</td>\n",
       "      <td>...</td>\n",
       "      <td>0.090088</td>\n",
       "      <td>0.015022</td>\n",
       "      <td>0.018651</td>\n",
       "      <td>26.359732</td>\n",
       "      <td>0.840820</td>\n",
       "      <td>0.054976</td>\n",
       "      <td>0.031738</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.328013</td>\n",
       "      <td>0.079193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3765</td>\n",
       "      <td>143979</td>\n",
       "      <td>4</td>\n",
       "      <td>4.442158</td>\n",
       "      <td>10.669847</td>\n",
       "      <td>3.940961</td>\n",
       "      <td>1.567164</td>\n",
       "      <td>0.490692</td>\n",
       "      <td>-0.452973</td>\n",
       "      <td>-0.212948</td>\n",
       "      <td>0.164879</td>\n",
       "      <td>...</td>\n",
       "      <td>0.095396</td>\n",
       "      <td>0.019743</td>\n",
       "      <td>0.021407</td>\n",
       "      <td>4.454741</td>\n",
       "      <td>0.453613</td>\n",
       "      <td>0.077846</td>\n",
       "      <td>0.062988</td>\n",
       "      <td>0.001465</td>\n",
       "      <td>1.859602</td>\n",
       "      <td>0.066624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1310</td>\n",
       "      <td>48820</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.517542</td>\n",
       "      <td>0.001574</td>\n",
       "      <td>-0.178640</td>\n",
       "      <td>-0.108170</td>\n",
       "      <td>-0.252360</td>\n",
       "      <td>0.278714</td>\n",
       "      <td>-0.854324</td>\n",
       "      <td>0.411887</td>\n",
       "      <td>...</td>\n",
       "      <td>0.093371</td>\n",
       "      <td>0.025141</td>\n",
       "      <td>0.020462</td>\n",
       "      <td>6.162170</td>\n",
       "      <td>0.284180</td>\n",
       "      <td>0.048311</td>\n",
       "      <td>0.035645</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.079569</td>\n",
       "      <td>0.039280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3769</td>\n",
       "      <td>144175</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.390341</td>\n",
       "      <td>0.436722</td>\n",
       "      <td>-0.609044</td>\n",
       "      <td>-0.538162</td>\n",
       "      <td>0.086064</td>\n",
       "      <td>-0.741646</td>\n",
       "      <td>-0.939368</td>\n",
       "      <td>-0.657182</td>\n",
       "      <td>...</td>\n",
       "      <td>0.113712</td>\n",
       "      <td>0.026862</td>\n",
       "      <td>0.034028</td>\n",
       "      <td>40.887131</td>\n",
       "      <td>0.743652</td>\n",
       "      <td>0.050757</td>\n",
       "      <td>0.041016</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.673950</td>\n",
       "      <td>0.046759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2511</td>\n",
       "      <td>91937</td>\n",
       "      <td>3</td>\n",
       "      <td>2.130329</td>\n",
       "      <td>-0.097011</td>\n",
       "      <td>0.293347</td>\n",
       "      <td>-0.371048</td>\n",
       "      <td>1.435453</td>\n",
       "      <td>1.242170</td>\n",
       "      <td>1.015294</td>\n",
       "      <td>1.811976</td>\n",
       "      <td>...</td>\n",
       "      <td>0.097805</td>\n",
       "      <td>0.021688</td>\n",
       "      <td>0.027949</td>\n",
       "      <td>56.397892</td>\n",
       "      <td>0.331543</td>\n",
       "      <td>0.024451</td>\n",
       "      <td>0.020508</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.723203</td>\n",
       "      <td>0.019159</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 520 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      track_id  genre_id        01         02        03        04        05  \\\n",
       "3544    133294         6  0.133676   1.219621  1.041329  0.659568  0.661551   \n",
       "1023     40237         3 -0.634775  -0.452372 -0.081961  0.020517 -0.575869   \n",
       "3698    140872         3 -1.081832  -1.001203  0.902922  0.164892 -0.614164   \n",
       "272      11419         1 -0.768838  -0.667095 -0.604739 -0.180145 -0.846874   \n",
       "620      24331         6 -0.504906  -0.532965 -0.224551 -0.419990 -0.410279   \n",
       "1950     69198         2  0.750938   0.909248  4.442852  2.286593  1.375715   \n",
       "3765    143979         4  4.442158  10.669847  3.940961  1.567164  0.490692   \n",
       "1310     48820         3 -0.517542   0.001574 -0.178640 -0.108170 -0.252360   \n",
       "3769    144175         4 -0.390341   0.436722 -0.609044 -0.538162  0.086064   \n",
       "2511     91937         3  2.130329  -0.097011  0.293347 -0.371048  1.435453   \n",
       "\n",
       "            06        07        08  ...     04.41     05.41     06.41  \\\n",
       "3544  0.840704  1.389098  1.094413  ...  0.063345  0.016298  0.018405   \n",
       "1023 -0.431036 -0.426676 -0.382549  ...  0.097534  0.017034  0.017351   \n",
       "3698 -0.655986 -0.119395  5.273300  ...  0.152206  0.030529  0.025080   \n",
       "272  -0.380538 -0.984623 -0.918730  ...  0.140241  0.036428  0.028642   \n",
       "620   0.823258  0.188249 -0.768032  ...  0.168203  0.034010  0.031814   \n",
       "1950  2.297371 -0.726958 -0.612376  ...  0.090088  0.015022  0.018651   \n",
       "3765 -0.452973 -0.212948  0.164879  ...  0.095396  0.019743  0.021407   \n",
       "1310  0.278714 -0.854324  0.411887  ...  0.093371  0.025141  0.020462   \n",
       "3769 -0.741646 -0.939368 -0.657182  ...  0.113712  0.026862  0.034028   \n",
       "2511  1.242170  1.015294  1.811976  ...  0.097805  0.021688  0.027949   \n",
       "\n",
       "           01.70     01.71     01.72     01.73     01.74      01.75     01.76  \n",
       "3544    3.186660  0.575195  0.092824  0.066406  0.000977   1.689548  0.080830  \n",
       "1023   16.264420  0.691406  0.073199  0.055176  0.009766   2.996620  0.062984  \n",
       "3698   30.582483  0.436523  0.025041  0.014160  0.004883   5.332044  0.046589  \n",
       "272    35.297848  0.337891  0.030125  0.024414  0.000000   5.388410  0.027061  \n",
       "620   295.583923  0.840332  0.021472  0.014648  0.000000  15.710932  0.040361  \n",
       "1950   26.359732  0.840820  0.054976  0.031738  0.000000   4.328013  0.079193  \n",
       "3765    4.454741  0.453613  0.077846  0.062988  0.001465   1.859602  0.066624  \n",
       "1310    6.162170  0.284180  0.048311  0.035645  0.000000   2.079569  0.039280  \n",
       "3769   40.887131  0.743652  0.050757  0.041016  0.000000   4.673950  0.046759  \n",
       "2511   56.397892  0.331543  0.024451  0.020508  0.000000   5.723203  0.019159  \n",
       "\n",
       "[10 rows x 520 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Croisement features/tracks du dataset train\n",
    "\n",
    "# Nom des features\n",
    "features = pd.read_csv(filepath_or_buffer=\"features_head.csv\", sep=\",\")\n",
    "print(features.columns)\n",
    "#print(features)\n",
    "print(\"#################\")\n",
    "\n",
    "# Croisement features/tracks du dataset train\n",
    "traingenre = pd.read_csv(filepath_or_buffer=\"train_clean.csv\", sep=\",\")\n",
    "iter_csv = pd.read_csv(filepath_or_buffer=\"features_adapte.csv\", sep=\",\", iterator=True, chunksize=10000)\n",
    "datatrain = pd.concat([chunk for chunk in iter_csv])\n",
    "\n",
    "data = pd.merge(traingenre, datatrain, on='track_id')\n",
    "data.sample(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x : (3995, 518) , y : (3995,)\n"
     ]
    }
   ],
   "source": [
    "# training sets\n",
    "x = data.drop(['genre_id', 'track_id'], axis=1)\n",
    "y = data['genre_id'].values\n",
    "\n",
    "print(\"x :\", x.shape, \", y :\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train : (3196, 518) , y_train : (3196,)\n",
      "x_test : (799, 518) , y_test : (799,)\n"
     ]
    }
   ],
   "source": [
    "# split train test\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
    "\n",
    "print(\"x_train :\", x_train.shape, \", y_train :\", y_train.shape)\n",
    "print(\"x_test :\", x_test.shape, \", y_test :\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_train: 7.289002228542061e-17. std_train: 0.996131513545271\n"
     ]
    }
   ],
   "source": [
    "# normalisation\n",
    "scaler = preprocessing.StandardScaler().fit(x_train)\n",
    "x_train = scaler.transform(x_train)\n",
    "x_test = scaler.transform(x_test)\n",
    "\n",
    "mean_train = x_train.mean()\n",
    "std_train = x_train.std()\n",
    "print(f'mean_train: {mean_train}. std_train: {std_train}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Premier modèle : K nearest neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=1, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_model = KNeighborsClassifier(n_neighbors=1)\n",
    "knn_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.82      0.90      0.86        88\n",
      "           2       0.54      0.36      0.43       105\n",
      "           3       0.63      0.50      0.56       109\n",
      "           4       0.57      0.52      0.54       110\n",
      "           5       0.37      0.69      0.49        97\n",
      "           6       0.46      0.22      0.30       100\n",
      "           7       0.27      0.33      0.30        95\n",
      "           8       0.45      0.51      0.48        95\n",
      "\n",
      "    accuracy                           0.50       799\n",
      "   macro avg       0.52      0.50      0.49       799\n",
      "weighted avg       0.52      0.50      0.49       799\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = knn_model.predict(x_test)\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deuxième modèle : Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "                       max_features=None, max_leaf_nodes=16,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_model = DecisionTreeClassifier(max_leaf_nodes=16, min_samples_split=2)\n",
    "tree_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.65      0.71        88\n",
      "           2       0.34      0.17      0.23       105\n",
      "           3       0.44      0.63      0.52       109\n",
      "           4       0.44      0.49      0.46       110\n",
      "           5       0.60      0.22      0.32        97\n",
      "           6       0.33      0.21      0.26       100\n",
      "           7       0.18      0.40      0.25        95\n",
      "           8       0.53      0.48      0.51        95\n",
      "\n",
      "    accuracy                           0.41       799\n",
      "   macro avg       0.46      0.41      0.41       799\n",
      "weighted avg       0.45      0.41      0.40       799\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = tree_model.predict(x_test)\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Troisième modèle : Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/janerussel/anaconda3/envs/IA/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=16,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest_model = RandomForestClassifier(max_leaf_nodes=16, min_samples_split=2)\n",
    "forest_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.69      0.84      0.76        88\n",
      "           2       0.35      0.27      0.30       105\n",
      "           3       0.50      0.66      0.57       109\n",
      "           4       0.47      0.62      0.54       110\n",
      "           5       0.39      0.37      0.38        97\n",
      "           6       0.35      0.22      0.27       100\n",
      "           7       0.35      0.14      0.20        95\n",
      "           8       0.52      0.73      0.61        95\n",
      "\n",
      "    accuracy                           0.48       799\n",
      "   macro avg       0.45      0.48      0.45       799\n",
      "weighted avg       0.45      0.48      0.45       799\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = forest_model.predict(x_test)\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quatrième méthode : Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "                           learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "                           max_features=None, max_leaf_nodes=None,\n",
       "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                           min_samples_leaf=1, min_samples_split=2,\n",
       "                           min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                           n_iter_no_change=None, presort='auto',\n",
       "                           random_state=None, subsample=1.0, tol=0.0001,\n",
       "                           validation_fraction=0.1, verbose=0,\n",
       "                           warm_start=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient_model = GradientBoostingClassifier()\n",
    "gradient_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.87      0.86      0.87        88\n",
      "           2       0.52      0.42      0.47       105\n",
      "           3       0.68      0.64      0.66       109\n",
      "           4       0.57      0.60      0.58       110\n",
      "           5       0.59      0.63      0.61        97\n",
      "           6       0.55      0.48      0.51       100\n",
      "           7       0.26      0.34      0.30        95\n",
      "           8       0.66      0.67      0.67        95\n",
      "\n",
      "    accuracy                           0.58       799\n",
      "   macro avg       0.59      0.58      0.58       799\n",
      "weighted avg       0.59      0.58      0.58       799\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = gradient_model.predict(x_test)\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cinquième méthode : XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
       "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
       "              nthread=None, objective='multi:softprob', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "              silent=None, subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_model = xgb.XGBClassifier()\n",
    "xgb_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.88      0.91      0.89        88\n",
      "           2       0.52      0.50      0.51       105\n",
      "           3       0.66      0.72      0.69       109\n",
      "           4       0.57      0.63      0.60       110\n",
      "           5       0.59      0.56      0.57        97\n",
      "           6       0.56      0.45      0.50       100\n",
      "           7       0.31      0.32      0.31        95\n",
      "           8       0.60      0.63      0.62        95\n",
      "\n",
      "    accuracy                           0.59       799\n",
      "   macro avg       0.59      0.59      0.59       799\n",
      "weighted avg       0.59      0.59      0.59       799\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = xgb_model.predict(x_test)\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
       "              learning_rate=0.2, max_delta_step=0, max_depth=3,\n",
       "              min_child_weight=1, missing=None, n_estimators=200, n_jobs=1,\n",
       "              nthread=None, objective='multi:softprob', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "              silent=None, subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_model = xgb.XGBClassifier(n_estimators=200, learning_rate=0.2, max_depth=3, min_child_weight=1)\n",
    "xgb_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.88      0.92      0.90        88\n",
      "           2       0.54      0.52      0.53       105\n",
      "           3       0.69      0.67      0.68       109\n",
      "           4       0.66      0.66      0.66       110\n",
      "           5       0.66      0.67      0.66        97\n",
      "           6       0.54      0.48      0.51       100\n",
      "           7       0.40      0.42      0.41        95\n",
      "           8       0.63      0.66      0.65        95\n",
      "\n",
      "    accuracy                           0.62       799\n",
      "   macro avg       0.62      0.63      0.62       799\n",
      "weighted avg       0.62      0.62      0.62       799\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = xgb_model.predict(x_test)\n",
    "print(classification_report(y_test,y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
