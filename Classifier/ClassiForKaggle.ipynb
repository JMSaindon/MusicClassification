{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import random as rd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data merged : (3995, 541) , train genre : (3995, 2) , train data : (3997, 540)\n",
      "test data: (4006, 540)\n",
      "all test id: 4008\n"
     ]
    }
   ],
   "source": [
    "# Croisement features/tracks du dataset train\n",
    "traingenre = pd.read_csv(filepath_or_buffer=\"train_clean.csv\", sep=\",\")\n",
    "datatrain = pd.read_csv(filepath_or_buffer=\"train_data.csv\", sep=\",\")\n",
    "\n",
    "train_data = pd.merge(traingenre, datatrain, on='track_id')\n",
    "print(\"data merged :\",train_data.shape, \", train genre :\", traingenre.shape, \", train data :\", datatrain.shape)\n",
    "train_data.sample(n=10)\n",
    "\n",
    "test_data = pd.read_csv(filepath_or_buffer=\"test_data.csv\", sep=\",\")\n",
    "print(f\"test data: {test_data.shape}\")\n",
    "\n",
    "all_test_id = pd.read_csv(filepath_or_buffer=\"submission.csv\", sep=\",\")\n",
    "all_test_id.drop(['genre_id'], axis=1, inplace=True)\n",
    "print(f\"all test id: {len(all_test_id)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train: (3995, 539), y_train: (3995,), x_test: (4006, 539)\n"
     ]
    }
   ],
   "source": [
    "# training sets\n",
    "x_train = train_data.drop(['genre_id', 'track_id'], axis=1)\n",
    "y_train = train_data['genre_id'].values\n",
    "x_test  = test_data.drop(['track_id'], axis=1)\n",
    "test_id = test_data['track_id'].values\n",
    "\n",
    "print(f\"x_train: {x_train.shape}, y_train: {y_train.shape}, x_test: {x_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_train: 3.3241958385120774e-17. std_train: 1.0\n"
     ]
    }
   ],
   "source": [
    "# normalisation\n",
    "scaler = preprocessing.StandardScaler().fit(x_train)\n",
    "x_train = scaler.transform(x_train)\n",
    "x_test = scaler.transform(x_test)\n",
    "\n",
    "mean_train = x_train.mean()\n",
    "std_train = x_train.std()\n",
    "\n",
    "print(f'mean_train: {mean_train}. std_train: {std_train}')\n",
    "assert np.abs(np.max(mean_train)) < 10**-6\n",
    "assert np.abs(np.max(std_train - 1)) < 10**-6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
       "              learning_rate=0.2, max_delta_step=0, max_depth=5,\n",
       "              min_child_weight=3, missing=None, n_estimators=180, n_jobs=1,\n",
       "              nthread=None, objective='multi:softprob', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "              silent=None, subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = xgb.XGBClassifier(n_estimators=180, learning_rate=0.2, max_depth=5, min_child_weight=3)\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_test)\n",
    "\n",
    "assert len(y_pred) == len(test_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create kaggle csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted id: 4006, submitting 4008 ids\n"
     ]
    }
   ],
   "source": [
    "output_data = pd.DataFrame({'track_id': test_id, 'genre_id': y_pred})\n",
    "output_data = output_data.merge(all_test_id, on='track_id', how='right')\n",
    "\n",
    "# fill missing id with a random genre\n",
    "output_data['genre_id'] = output_data['genre_id'].apply(lambda x: rd.randint(1,8) if np.isnan(x) else x)\n",
    "\n",
    "output_data['genre_id'] = output_data['genre_id'].apply(int)\n",
    "output_data.set_index('track_id', inplace=True)\n",
    "print(f\"predicted id: {len(test_id)}, submitting {len(output_data)} ids\")\n",
    "\n",
    "output_data.to_csv('genreForKaggle.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
